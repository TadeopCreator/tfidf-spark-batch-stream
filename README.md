# TF-IDF implementation using Spark (Batch and Streaming)

This repository contains implementations of the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm using Apache Spark for both batch and streaming processing.

## Batch Processing

The batch implementation of TF-IDF involves processing the entire dataset at once.

## Streaming Processing

The streaming implementation of TF-IDF involves processing data in real-time as it arrives.

### How to Run

To execute the batch processing code:

1. Install Spark for Python.
2. Set up the necessary environment variables.
3. Mount Google Drive if required for accessing datasets or files.
4. Run the provided code cells step by step in a Jupyter Notebook/Google Colab environment.

## Folder Structure

- `batch_processing/`: Contains code and datasets for batch processing.
- `streaming_processing/`: Contains code for streaming processing.

## Instructions

### Batch Processing

- Navigate to the `batch_processing/` directory.
- Open and run the Jupyter Notebook named `TF-IDF_Batch_Processing.ipynb`.

### Streaming Processing

- Navigate to the `streaming_processing/` directory.
- Open and run the Jupyter Notebook named `TF-IDF_Streaming_Processing.ipynb`.

## References

- [Apache Spark Documentation](https://spark.apache.org/documentation.html): Official documentation for Apache Spark.
- [PySpark API Documentation](https://spark.apache.org/docs/latest/api/python/index.html): PySpark API reference.

## Note

Feel free to contribute or provide feedback to improve these implementations.
